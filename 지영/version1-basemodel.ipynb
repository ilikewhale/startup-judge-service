{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3396a68b",
   "metadata": {},
   "source": [
    "\n",
    "- ë²•ë¥ /ê·œì œ ë¦¬ìŠ¤í¬ëŠ” í˜„ì¬ ê¸°ìˆ ë ¥ì—ì„œ ë¯¸ë˜ì— ë¬¸ì œê°€ ë ë§Œí•œ ê±°ë‹ˆê¹Œ ì´ê±° ë…¸ë“œ ìœ„ì¹˜ ë³€ê²½í•˜ëŠ”ê²Œ ì¢‹ì„ë“¯\n",
    "- ê·¸ë¦¬ê³  ì›¹ ê²€ìƒ‰ í•„ìˆ˜ë¡œ í•˜ëŠ”ê²Œ ì¢‹ì„ ê²ƒ ê°™ì€ë° ê³ ë¯¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4e2b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_teddynote import logging\n",
    "from langchain_opentutorial.rag.pdf import PDFRetrievalChain\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import Annotated, Sequence, TypedDict, Literal, List, Dict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import asyncio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c180e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "\n",
    "    industry: str\n",
    "    region: str\n",
    "\n",
    "    startup_list: List[str]                   # ìŠ¤íƒ€íŠ¸ì—… íƒìƒ‰ ì—ì´ì „íŠ¸ê°€ ìƒì„±í•˜ëŠ” ì£¼ìš” ê¸°ì—…ëª… ëª©ë¡\n",
    "    startup_profiles: Dict[str, Dict]         # ìŠ¤íƒ€íŠ¸ì—…ë³„ ì •ë³´ ì¢…í•© ì €ì¥ì†Œ\n",
    "    tech_summary : Dict[str, str]              # ê° ìŠ¤íƒ€íŠ¸ì—… ê¸°ìˆ  ìš”ì•½ ì •ë³´\n",
    "    founder_reputation : Dict[str, Dict]       # ì°½ì—…ì ì´ë ¥ + í‰íŒ ì •ë³´\n",
    "    market_analysis: Dict[str, Dict]          # ì‹œì¥ì„± í‰ê°€ ê²°ê³¼\n",
    "    legal_risk: Dict[str, str]                # ë²•ì /ê·œì œ ì´ìŠˆ ìš”ì•½\n",
    "    competitor_info: Dict[str, Dict]          # ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„\n",
    "    investment_decision: Dict[str, str]       # íˆ¬ì íŒë‹¨ (íˆ¬ì / ë³´ë¥˜ + ì‚¬ìœ )\n",
    "    final_report: str                          # ë³´ê³ ì„œ ìƒì„± ì—ì´ì „íŠ¸ì˜ ì¶œë ¥ë¬¼ (PDF or Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb095533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "CH15-Agentic-RAG-Legal\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_teddynote import logging\n",
    "from langchain_opentutorial.rag.pdf import PDFRetrievalChain\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import Annotated, Sequence, TypedDict, Literal\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langchain_teddynote.messages import stream_graph\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "logging.langsmith(\"CH15-Agentic-RAG-Legal\")\n",
    "\n",
    "# ë²•ì  ë¦¬ìŠ¤í¬ ë¶„ì„ ìƒíƒœ ì •ì˜\n",
    "class LegalRiskAgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    company: str\n",
    "    industry: str\n",
    "    region: str\n",
    "\n",
    "    legal_assessments: Dict[str, str]\n",
    "\n",
    "\n",
    "# ëª¨ë¸ ì´ë¦„ ì„¤ì •\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4)\n",
    "\n",
    "# PDF íŒŒì¼ë¡œë¶€í„° ê²€ìƒ‰ ì²´ì¸ ìƒì„±\n",
    "def create_pdf_retriever():\n",
    "    file_path = [\"data/2023 êµ­ë‚´ì™¸ AI ê·œì œ ë° ì •ì±… ë™í–¥.pdf\", \"data/ì¸ê³µì§€ëŠ¥(AI) ê´€ë ¨ êµ­ë‚´ì™¸ ë²•ì œ ë™í–¥.pdf\"]\n",
    "    pdf_file = PDFRetrievalChain(file_path).create_chain()\n",
    "    pdf_retriever = pdf_file.retriever\n",
    "    \n",
    "    # PDF ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ ë„êµ¬ ìƒì„±\n",
    "    retriever_tool = create_retriever_tool(\n",
    "        pdf_retriever,\n",
    "        \"legal_pdf_retriever\",\n",
    "        \"Search and return information about AI legal and regulatory frameworks from the PDF files. They contain essential information on AI regulations, policies, and legal trends relevant for AI startups. The documents are focused on both domestic and international AI legal frameworks.\",\n",
    "        document_prompt=PromptTemplate.from_template(\n",
    "            \"<document><context>{page_content}</context><metadata><source>{source}</source><page>{page}</page></metadata></document>\"\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    return retriever_tool\n",
    "\n",
    "# ë°ì´í„° ëª¨ë¸ ì •ì˜\n",
    "class grade(BaseModel):\n",
    "    \"\"\"A binary score for relevance checks\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"Response 'yes' if the document is relevant to the legal/regulatory question or 'no' if it is not.\"\n",
    "    )\n",
    "\n",
    "# ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ í•¨ìˆ˜ (ì¡°ê±´ë¶€ ì—£ì§€ì—ì„œ ì‚¬ìš©)\n",
    "def grade_documents(state: LegalRiskAgentState) -> str:\n",
    "    # LLM ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming=True)\n",
    "\n",
    "    # êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ìœ„í•œ LLM ì„¤ì •\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a legal expert assessing relevance of a retrieved document to an AI startup's legal/regulatory risk question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the question about AI legal/regulatory risks: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the legal/regulatory question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # llm + tool ë°”ì¸ë”© ì²´ì¸ ìƒì„±\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    # í˜„ì¬ ìƒíƒœì—ì„œ ë©”ì‹œì§€ ì¶”ì¶œ\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    question = messages[0].content\n",
    "\n",
    "    # ê²€ìƒ‰ëœ ë¬¸ì„œ ì¶”ì¶œ\n",
    "    retrieved_docs = last_message.content\n",
    "\n",
    "    # ê´€ë ¨ì„± í‰ê°€ ì‹¤í–‰\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": retrieved_docs})\n",
    "\n",
    "    # ê´€ë ¨ì„± ì—¬ë¶€ ì¶”ì¶œ\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    # ê´€ë ¨ì„± ì—¬ë¶€ì— ë”°ë¥¸ ê²°ì •\n",
    "    if score == \"yes\":\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(score)\n",
    "        return \"rewrite\"\n",
    "\n",
    "# ì´ˆê¸° ì§ˆì˜ ì²˜ë¦¬ ë…¸ë“œ\n",
    "def initial_query(state: LegalRiskAgentState):\n",
    "    print(\"\\nğŸŸ¢ [initial_query] ê¸°ì—… ì •ë³´ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„± ì¤‘...\")\n",
    "    question = f\"{state['company']}ì€(ëŠ”) {state['industry']} ë¶„ì•¼ AI ìŠ¤íƒ€íŠ¸ì—…ìœ¼ë¡œ, ê´€ë ¨ ë²•ì /ê·œì œ ë¦¬ìŠ¤í¬ëŠ” ë¬´ì—‡ì¸ê°€?\"\n",
    "    print(f\"â¤ ìƒì„±ëœ ì§ˆë¬¸: {question}\")\n",
    "    return {\"messages\": [HumanMessage(content=question)]}\n",
    "\n",
    "# ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ \n",
    "def pdf_retrieval(state: LegalRiskAgentState):\n",
    "    print(\"\\nğŸ“„ [pdf_retrieval] PDF ê¸°ë°˜ ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[-1].content\n",
    "    retriever_tool = create_pdf_retriever()\n",
    "    results = retriever_tool.invoke({\"query\": question})\n",
    "    print(\"âœ… ê²€ìƒ‰ ì™„ë£Œ - ê´€ë ¨ ë¬¸ì„œ ìš”ì•½ ë°˜í™˜\")\n",
    "    return {\"messages\": [HumanMessage(content=results)]}\n",
    "\n",
    "# ì§ˆì˜ ì¬ì‘ì„± ë…¸ë“œ\n",
    "def rewrite(state: LegalRiskAgentState):\n",
    "    print(\"\\nâœï¸ [rewrite] ë²•ì  ì§ˆë¬¸ì´ ë¬¸ì„œì™€ ê´€ë ¨ ì—†ìœ¼ë¯€ë¡œ ì§ˆì˜ ì¬ì‘ì„± ì‹œì‘\")\n",
    "    # í˜„ì¬ ìƒíƒœì—ì„œ ë©”ì‹œì§€ ì¶”ì¶œ\n",
    "    messages = state[\"messages\"]\n",
    "    # ì›ë˜ ì§ˆë¬¸ ì¶”ì¶œ\n",
    "    question = messages[0].content\n",
    "    company = state[\"company\"]\n",
    "    industry = state[\"industry\"]\n",
    "\n",
    "    # ì§ˆë¬¸ ê°œì„ ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input question about AI legal/regulatory risks for {company} in the {industry} industry and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question that focuses on specific legal/regulatory frameworks, compliance requirements, or potential legal risks for this AI startup: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # LLM ëª¨ë¸ë¡œ ì§ˆë¬¸ ê°œì„ \n",
    "    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming=True)\n",
    "    # Query-Transform ì²´ì¸ ì‹¤í–‰\n",
    "    response = model.invoke(msg)\n",
    "\n",
    "    # ì¬ì‘ì„±ëœ ì§ˆë¬¸ ë°˜í™˜\n",
    "    print(f\"ğŸ†• ì¬ì‘ì„±ëœ ì§ˆë¬¸: {response.content.strip()[:100]}...\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Web Search ë…¸ë“œ \n",
    "def web_search(state: LegalRiskAgentState):\n",
    "    print(\"\\nğŸŒ [web_search] ì›¹ ê¸°ë°˜ ë³´ì¡° ë²•ë¥  ì •ë³´ ê²€ìƒ‰ ì‹œì‘\")\n",
    "    tavily_tool = TavilySearch()\n",
    "    \n",
    "    # ìˆ˜ì •ëœ ë¶€ë¶„: messagesì—ì„œ ë‚´ìš© ì¶”ì¶œ\n",
    "    messages = state[\"messages\"]\n",
    "    search_query = messages[-1].content\n",
    "    \n",
    "    company = state[\"company\"]\n",
    "    industry = state[\"industry\"]\n",
    "    \n",
    "    # ê²€ìƒ‰ ì¿¼ë¦¬ì— ê¸°ì—… ì •ë³´ ì¶”ê°€\n",
    "    enhanced_query = f\"{search_query} {company} {industry} AI ìŠ¤íƒ€íŠ¸ì—… ë²•ì  ê·œì œ\"\n",
    "\n",
    "    search_result = tavily_tool.search(\n",
    "        query=enhanced_query,  # ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        topic=\"legal\",     # ë²•ë¥  ì£¼ì œë¡œ ë³€ê²½\n",
    "        max_results=3,       # ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼\n",
    "        format_output=True,  # ê²°ê³¼ í¬ë§·íŒ…\n",
    "    )\n",
    "    print(\"âœ… ì›¹ ê²€ìƒ‰ ì™„ë£Œ - ìš”ì•½ ë‚´ìš© ë°˜í™˜\")\n",
    "    return {\"messages\": [HumanMessage(content=search_result)]}\n",
    "\n",
    "\n",
    "\n",
    "# ë²•ì  ë¶„ì„ ë…¸ë“œ\n",
    "def analyze(state: LegalRiskAgentState):\n",
    "    print(\"\\nğŸ§  [analyze] ë¬¸ì„œ ê¸°ë°˜ ë²•ì  ë¦¬ìŠ¤í¬ ë¶„ì„ ì‹¤í–‰\")\n",
    "    # í˜„ì¬ ìƒíƒœì—ì„œ ë©”ì‹œì§€ ì¶”ì¶œ\n",
    "    messages = state[\"messages\"]\n",
    "    # ì›ë˜ ì§ˆë¬¸ ì¶”ì¶œ\n",
    "    question = messages[0].content\n",
    "    company = state[\"company\"]\n",
    "    industry = state[\"industry\"]\n",
    "\n",
    "    # ê°€ì¥ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì¶”ì¶œ (ê²€ìƒ‰ ê²°ê³¼)\n",
    "    docs = messages[-1].content\n",
    "    \n",
    "    # ë””ë²„ê·¸ ë©”ì‹œì§€ ì¶”ê°€\n",
    "    print(f\"ê¸°ì—…: {company}\")\n",
    "    print(f\"ì‚°ì—…: {industry}\")\n",
    "    print(f\"ì§ˆë¬¸: {question}\")\n",
    "    print(f\"ë¬¸ì„œ ê¸¸ì´: {len(docs) if docs else 0}ì\")\n",
    "\n",
    "    # RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a legal expert specialized in AI regulations and policies for startups. \n",
    "        Use the following pieces of context to answer the question at the end about {company} in the {industry} industry. \n",
    "        If you don't know the answer, just say you don't know. \n",
    "        Don't try to make up an answer.\n",
    "        \n",
    "        Always structure your response in the following format: (ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€)\n",
    "        1. Legal/Regulatory Analysis: Provide a concise analysis of the legal and regulatory considerations.\n",
    "        2. Potential Risks: Outline specific risks the AI startup might face.\n",
    "        3. Compliance Recommendations: Suggest practical steps for ensuring compliance.\n",
    "        4. International Considerations: Briefly mention any relevant international frameworks if applicable.\n",
    "        \n",
    "        {context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Helpful Answer:\"\"\",\n",
    "        input_variables=[\"context\", \"question\", \"company\", \"industry\"],\n",
    "    )\n",
    "\n",
    "    # LLM ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0, streaming=True)\n",
    "\n",
    "    # RAG ì²´ì¸ êµ¬ì„±\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    try:\n",
    "        # ë‹µë³€ ìƒì„± ì‹¤í–‰\n",
    "        response = rag_chain.invoke({\n",
    "            \"context\": docs, \n",
    "            \"question\": question,\n",
    "            \"company\": company,\n",
    "            \"industry\": industry\n",
    "        })\n",
    "        print(\"âœ… ë¶„ì„ ì™„ë£Œ - ìš”ì•½ ë³´ê³  ìƒì„±\")\n",
    "        return {\"messages\": [HumanMessage(content=response)]}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        error_msg = f\"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "        return {\"messages\": [HumanMessage(content=error_msg)]}\n",
    "\n",
    "# ë²•ì /ê·œì œ ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ ë…¸ë“œ\n",
    "def analyze_legal_risks(state: LegalRiskAgentState):\n",
    "    print(\"\\nğŸ“Š [analyze_legal_risks] ìµœì¢… í‰ê°€ ë‚´ìš© ì €ì¥\")\n",
    "    company = state[\"company\"]\n",
    "    messages = state[\"messages\"]\n",
    "    legal_assessment = messages[-1].content\n",
    "    \n",
    "    print(f\"ğŸ“ ì €ì¥ëœ í‰ê°€: {legal_assessment[:100]}...\")\n",
    "    return {\n",
    "        \"legal_assessments\": {company: legal_assessment}\n",
    "    }\n",
    "\n",
    "# Agentic RAGë¥¼ ì‚¬ìš©í•œ ë²•ì /ê·œì œ ë¦¬ìŠ¤í¬ ë¶„ì„ ê·¸ë˜í”„ ìƒì„±\n",
    "def create_legal_risk_graph():\n",
    "    \"\"\"ë²•ì  ë¦¬ìŠ¤í¬ ë¶„ì„ì„ ìœ„í•œ LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„± í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    # ê·¸ë˜í”„ ì •ì˜\n",
    "    workflow = StateGraph(LegalRiskAgentState)\n",
    "\n",
    "    # ë…¸ë“œ ì •ì˜\n",
    "    workflow.add_node(\"initial_query\", initial_query)  # ì´ˆê¸° ì§ˆì˜ ì²˜ë¦¬\n",
    "    workflow.add_node(\"pdf_retrieval\", pdf_retrieval)  # PDF ë¬¸ì„œ ê²€ìƒ‰\n",
    "    workflow.add_node(\"rewrite\", rewrite)             # ì§ˆì˜ ì¬ì‘ì„±\n",
    "    workflow.add_node(\"web_search\", web_search)       # ì›¹ ê²€ìƒ‰\n",
    "    workflow.add_node(\"analyze\", analyze)             # ë²•ì  ë¶„ì„\n",
    "    workflow.add_node(\"legal_risks\", analyze_legal_risks)  # ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬\n",
    "\n",
    "    # ì—£ì§€ ì •ì˜\n",
    "    workflow.add_edge(START, \"initial_query\")\n",
    "    workflow.add_edge(\"initial_query\", \"pdf_retrieval\")\n",
    "\n",
    "    # ì¡°ê±´ë¶€ ì—£ì§€: ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ì„±ì— ë”°ë¼ ë¶„ê¸°\n",
    "    workflow.add_conditional_edges(\n",
    "        \"pdf_retrieval\",\n",
    "        grade_documents,\n",
    "        {\n",
    "            \"generate\": \"analyze\",      # ê´€ë ¨ì„± ìˆìœ¼ë©´ ë¶„ì„\n",
    "            \"rewrite\": \"rewrite\"        # ê´€ë ¨ì„± ì—†ìœ¼ë©´ ì¬ì‘ì„±\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ì¬ì‘ì„± í›„ ì›¹ ê²€ìƒ‰ ì§„í–‰\n",
    "    workflow.add_edge(\"rewrite\", \"web_search\")\n",
    "    \n",
    "    # ì›¹ ê²€ìƒ‰ í›„ ë¶„ì„ ì§„í–‰\n",
    "    workflow.add_edge(\"web_search\", \"analyze\")\n",
    "    \n",
    "    # ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ ë° ì¢…ë£Œ\n",
    "    workflow.add_edge(\"analyze\", \"legal_risks\")\n",
    "    workflow.add_edge(\"legal_risks\", END)\n",
    "\n",
    "    # ê·¸ë˜í”„ ì»´íŒŒì¼ ë° ë°˜í™˜\n",
    "    return workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e822c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c167476",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_state: AgentState = {\n",
    "    \"industry\": \"AI ì˜ë£Œ\",\n",
    "    \"region\": \"ëŒ€í•œë¯¼êµ­\",\n",
    "\n",
    "    \"startup_list\": [\"AIí—¬ìŠ¤ì¼€ì–´\", \"ë‹¥í„°AI\"],\n",
    "    \n",
    "    \"startup_profiles\": {\n",
    "        \"AIí—¬ìŠ¤ì¼€ì–´\": {\"ì„¤ë¦½ì—°ë„\": 2020, \"ì§ì› ìˆ˜\": 15},\n",
    "        \"ë‹¥í„°AI\": {\"ì„¤ë¦½ì—°ë„\": 2021, \"ì§ì› ìˆ˜\": 10}\n",
    "    },\n",
    "\n",
    "    \"tech_summary\": {\n",
    "        \"AIí—¬ìŠ¤ì¼€ì–´\": \"ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì˜ìƒ ì§„ë‹¨ ì†”ë£¨ì…˜\",\n",
    "        \"ë‹¥í„°AI\": \"AI ê¸°ë°˜ ì²˜ë°© ìµœì í™” API\"\n",
    "    },\n",
    "\n",
    "    \"founder_reputation\": {\n",
    "        \"AIí—¬ìŠ¤ì¼€ì–´\": {\"ì´ë¦„\": \"í™ê¸¸ë™\", \"ì´ë ¥\": \"ì„œìš¸ëŒ€ ì˜ëŒ€ â†’ KAIST AI Lab\", \"ë¦¬ìŠ¤í¬\": \"ì—†ìŒ\"},\n",
    "        \"ë‹¥í„°AI\": {\"ì´ë¦„\": \"ê¹€ì˜í¬\", \"ì´ë ¥\": \"IBM Watson Health\", \"ë¦¬ìŠ¤í¬\": \"ì „ì§ íˆ¬ì ê´€ë ¨ ë¶„ìŸ ì´ë ¥ ìˆìŒ\"}\n",
    "    },\n",
    "\n",
    "    \"market_analysis\": {\n",
    "        \"AIí—¬ìŠ¤ì¼€ì–´\": {\"ì‹œì¥ ê·œëª¨\": \"500ì–µ\", \"ê²½ìŸ ê°•ë„\": \"ì¤‘ê°„\"},\n",
    "        \"ë‹¥í„°AI\": {\"ì‹œì¥ ê·œëª¨\": \"300ì–µ\", \"ê²½ìŸ ê°•ë„\": \"ë†’ìŒ\"}\n",
    "    },\n",
    "\n",
    "    \"legal_risk\": {\n",
    "        \"AIí—¬ìŠ¤ì¼€ì–´\": \"ì˜ë£Œ ë°ì´í„° ë¹„ì‹ë³„í™” ì´ìŠˆ ì¡´ì¬\",\n",
    "        \"ë‹¥í„°AI\": \"ì²˜ë°© ì‹œìŠ¤í…œì˜ ì¸ì¦ ìš”ê±´ ë¯¸ì¶©ì¡±\"\n",
    "    },\n",
    "\n",
    "    \"competitor_info\": {\n",
    "        \"AIí—¬ìŠ¤ì¼€ì–´\": {\"ì£¼ìš” ê²½ìŸì‚¬\": [\"ë©”ë””ì—ì´ì•„ì´\", \"ë”¥ë©”ë“œ\"], \"ì°¨ë³„ì \": \"êµ­ë‚´ ìœ ì¼ ì˜ìƒ ê¸°ë°˜ ì§„ë‹¨\"},\n",
    "        \"ë‹¥í„°AI\": {\"ì£¼ìš” ê²½ìŸì‚¬\": [\"í—¬ë¡œë‹¥\"], \"ì°¨ë³„ì \": \"ì²˜ë°© ì¶”ì²œì— ê°•í™”í•™ìŠµ ì‚¬ìš©\"}\n",
    "    },\n",
    "\n",
    "    \"investment_decision\": {\n",
    "        \"AIí—¬ìŠ¤ì¼€ì–´\": \"íˆ¬ì - ê¸°ìˆ  ìš°ìˆ˜ì„±ê³¼ ê·œì œ ì í•©ì„± í™•ë³´\",\n",
    "        \"ë‹¥í„°AI\": \"ë³´ë¥˜ - ë²•ì  ì´ìŠˆ ì¶”ê°€ ê²€í†  í•„ìš”\"\n",
    "    },\n",
    "\n",
    "    \"final_report\": \"[ë³´ê³ ì„œ ë¯¸ìƒì„±]\"  # ì´í›„ ë³´ê³ ì„œ ìƒì„± ë…¸ë“œì—ì„œ ê°±ì‹ \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a96e842f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¢ [initial_query] ê¸°ì—… ì •ë³´ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„± ì¤‘...\n",
      "â¤ ìƒì„±ëœ ì§ˆë¬¸: ë‹¥í„°AIì€(ëŠ”) ì˜ë£Œ AI ë¶„ì•¼ AI ìŠ¤íƒ€íŠ¸ì—…ìœ¼ë¡œ, ê´€ë ¨ ë²•ì /ê·œì œ ë¦¬ìŠ¤í¬ëŠ” ë¬´ì—‡ì¸ê°€?\n",
      "\n",
      "ğŸ“„ [pdf_retrieval] PDF ê¸°ë°˜ ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘\n",
      "âœ… ê²€ìƒ‰ ì™„ë£Œ - ê´€ë ¨ ë¬¸ì„œ ìš”ì•½ ë°˜í™˜\n",
      "\n",
      "ğŸ§  [analyze] ë¬¸ì„œ ê¸°ë°˜ ë²•ì  ë¦¬ìŠ¤í¬ ë¶„ì„ ì‹¤í–‰\n",
      "ê¸°ì—…: ë‹¥í„°AI\n",
      "ì‚°ì—…: ì˜ë£Œ AI\n",
      "ì§ˆë¬¸: ë‹¥í„°AIì˜ ë²•ì  ê·œì œ ë¶„ì„\n",
      "ë¬¸ì„œ ê¸¸ì´: 3944ì\n",
      "âœ… ë¶„ì„ ì™„ë£Œ - ìš”ì•½ ë³´ê³  ìƒì„±\n",
      "\n",
      "ğŸ“Š [analyze_legal_risks] ìµœì¢… í‰ê°€ ë‚´ìš© ì €ì¥\n",
      "ğŸ“ ì €ì¥ëœ í‰ê°€: 1. ë²•ì /ê·œì œ ë¶„ì„: ë‹¥í„°AIëŠ” ì˜ë£Œ AI ì‚°ì—…ì— ì†í•˜ë¯€ë¡œ, ê³ ìœ„í—˜ AI ì‹œìŠ¤í…œìœ¼ë¡œ ë¶„ë¥˜ë  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì´ì— ë”°ë¼ EU ì¸ê³µì§€ëŠ¥ë²• ë° êµ­ë‚´ ê´€ë ¨ ë²•ë ¹ì— ë”°ë¼ ì‹œì¥ ì¶œì‹œ ì „...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1. ë²•ì /ê·œì œ ë¶„ì„: ë‹¥í„°AIëŠ” ì˜ë£Œ AI ì‚°ì—…ì— ì†í•˜ë¯€ë¡œ, ê³ ìœ„í—˜ AI ì‹œìŠ¤í…œìœ¼ë¡œ ë¶„ë¥˜ë  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì´ì— ë”°ë¼ EU ì¸ê³µì§€ëŠ¥ë²• ë° êµ­ë‚´ ê´€ë ¨ ë²•ë ¹ì— ë”°ë¼ ì‹œì¥ ì¶œì‹œ ì „ ìœ„í—˜ì„± í‰ê°€ ë° ì¶œì‹œ í›„ ëª¨ë‹ˆí„°ë§ ì˜ë¬´ê°€ ë¶€ê³¼ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ê°œì¸ì •ë³´ ë³´í˜¸ì™€ ê´€ë ¨ëœ ë²•ë¥ ì„ ì¤€ìˆ˜í•´ì•¼ í•˜ë©°, AIì˜ ê²°ê³¼ë¬¼ì— ëŒ€í•œ ì„±ì‹¤ì˜ë¬´ë¥¼ ì´í–‰í•´ì•¼ í•©ë‹ˆë‹¤.\\n\\n2. ì ì¬ì  ìœ„í—˜: ë‹¥í„°AIëŠ” ê°œì¸ì •ë³´ ìœ ì¶œ, ì˜¤ì‘ë™ìœ¼ë¡œ ì¸í•œ ì•ˆì „ì‚¬ê³ , ê·¸ë¦¬ê³  AIì˜ ê²°ê³¼ë¬¼ì— ëŒ€í•œ ë²•ì  ì±…ì„ ë¬¸ì œ ë“± ë‹¤ì–‘í•œ ìœ„í—˜ì— ì§ë©´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ì˜ë£Œ ë¶„ì•¼ì—ì„œì˜ ì˜ëª»ëœ ì§„ë‹¨ì´ë‚˜ ì¹˜ë£Œ ê¶Œê³ ëŠ” ì‹¬ê°í•œ ë²•ì  ë¬¸ì œë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n3. ì¤€ìˆ˜ ê¶Œì¥ ì‚¬í•­: ë‹¥í„°AIëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì¡°ì¹˜ë¥¼ ì·¨í•´ì•¼ í•©ë‹ˆë‹¤. ì²«ì§¸, ê³ ìœ„í—˜ AI ì‹œìŠ¤í…œìœ¼ë¡œì„œì˜ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ê¸° ìœ„í•œ ìœ„í—˜ ê´€ë¦¬ ì²´ê³„ë¥¼ êµ¬ì¶•í•´ì•¼ í•©ë‹ˆë‹¤. ë‘˜ì§¸, ê°œì¸ì •ë³´ ë³´í˜¸ ê´€ë ¨ ë²•ë¥ ì„ ì¤€ìˆ˜í•˜ê¸° ìœ„í•´ ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬ ë°©ì¹¨ì„ ëª…í™•íˆ í•˜ê³ , ì‚¬ìš©ìì—ê²Œ íˆ¬ëª…í•˜ê²Œ ê³ ì§€í•´ì•¼ í•©ë‹ˆë‹¤. ì…‹ì§¸, AIì˜ ê²°ê³¼ë¬¼ì— ëŒ€í•œ ì •í™•ì„±ì„ ê²€í† í•˜ê³ , ì´ë¥¼ ë¬¸ì„œí™”í•˜ì—¬ ë²•ì  ì±…ì„ì„ ìµœì†Œí™”í•´ì•¼ í•©ë‹ˆë‹¤.\\n\\n4. êµ­ì œì  ê³ ë ¤ì‚¬í•­: EU ì¸ê³µì§€ëŠ¥ë²•ì„ í¬í•¨í•œ êµ­ì œì ì¸ AI ê·œì œ í”„ë ˆì„ì›Œí¬ëŠ” ë‹¥í„°AIì˜ ìš´ì˜ì— ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, EU ì‹œì¥ì— ì§„ì¶œí•  ê²½ìš° í•´ë‹¹ ë²•ë¥ ì„ ì¤€ìˆ˜í•´ì•¼ í•˜ë©°, êµ­ì œì ì¸ ìœ¤ë¦¬ ê¸°ì¤€ê³¼ ì‹ ë¢°ì„± ê¸°ì¤€ì„ ë”°ë¥´ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def legal_risk_analysis_agent(company, industry, region):\n",
    "    # ë²•ì /ê·œì œ ë¦¬ìŠ¤í¬ ê·¸ë˜í”„ ìƒì„±\n",
    "    legal_graph = create_legal_risk_graph()\n",
    "\n",
    "    # ì´ˆê¸° ìƒíƒœ ì„¤ì • (legal_assessments í•„ë“œ ì¶”ê°€)\n",
    "    initial_state: LegalRiskAgentState = {\n",
    "        \"messages\": [HumanMessage(content=f\"{company}ì˜ ë²•ì  ê·œì œ ë¶„ì„\")],\n",
    "        \"company\": company,\n",
    "        \"industry\": industry,\n",
    "        \"region\": region,\n",
    "        \"legal_assessments\": {}  # ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”\n",
    "    }\n",
    "\n",
    "    # ê·¸ë˜í”„ ì‹¤í–‰\n",
    "    result = await legal_graph.ainvoke(initial_state)\n",
    "\n",
    "    # ê²°ê³¼ ë°˜í™˜ (ìƒìœ„ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡)\n",
    "    if \"legal_assessments\" in result and company in result[\"legal_assessments\"]:\n",
    "        return result[\"legal_assessments\"][company]\n",
    "    else:\n",
    "        return \"ë²•ì  í‰ê°€ë¥¼ ì™„ë£Œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "await legal_risk_analysis_agent(\"ë‹¥í„°AI\", \"ì˜ë£Œ AI\", \"ê¸€ë¡œë²Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca459afc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e31268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84687792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e05db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c55e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8d609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57c8b80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
